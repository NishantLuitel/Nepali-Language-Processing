{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MlCbFiAZMXh4",
    "outputId": "1d54bbca-ddbd-4d2f-d3aa-3f995ef91260"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OR8zfjFpcQR5"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKtOlNG6oH-A"
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhN3Ao3PL8UV"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2k8VEHgim8jm"
   },
   "source": [
    "# Nepali Unicode Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNlzExnUne2D",
    "outputId": "0e54b5ff-2d69-49a3-bda3-98eca3a2564f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: nepali-unicode-converter in /usr/local/lib/python3.7/dist-packages (1.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install nepali-unicode-converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VVBfTttFGFkR",
    "outputId": "515cbc56-c621-439d-dba2-b218e49d86a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मेरो देश\n"
     ]
    }
   ],
   "source": [
    "from nepali_unicode_converter.convert import Converter\n",
    "converter = Converter()\n",
    "my_string = 'mero desha'\n",
    "converted_string = converter.convert(my_string)\n",
    "print(converted_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKSQKJ_6a41J"
   },
   "source": [
    "# Read and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZn_ok6QMqtl"
   },
   "outputs": [],
   "source": [
    "wordlists = PlaintextCorpusReader(\"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus\", '.*txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_zqYc7bML6S",
    "outputId": "c03c287e-fbb4-4b90-9a68-b79a8c89cc0a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6592/6592 [50:57<00:00,  2.16it/s]\n"
     ]
    }
   ],
   "source": [
    "texts,invalid = [],0\n",
    "for i in tqdm(wordlists.fileids()):\n",
    "    try:\n",
    "        texts.append(wordlists.raw(i).replace(\"\\ufeff\",\"\"))\n",
    "    except UnicodeDecodeError:\n",
    "        invalid+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n56ES8F-MLar",
    "outputId": "3bae5528-d3fc-497e-c832-d8685fcf3d5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6592"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlists.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7d3st4-YVKk",
    "outputId": "51ea223b-d156-4688-ebe8-9a1321964bbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDksMXcLYU-I",
    "outputId": "8900b93a-d76f-431f-e9ac-fd61e010b631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6592 0\n"
     ]
    }
   ],
   "source": [
    "print(len(texts), invalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AiiWtlmqYU2Y",
    "outputId": "fccb569d-bc70-4007-b9cf-c93e83f6fc51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/texts_list.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(texts, \"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/texts_list.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5bhCAM2YUuq"
   },
   "outputs": [],
   "source": [
    "texts = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/texts_list.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "vETGxmLtZYOd",
    "outputId": "b6264d9a-2f1b-4c67-e788-451d3d1211ac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'न्यूयोर्क—गैरआवासिय नेपाली संघ अमेरिकाको पाँचौ साधारणसभा जनवरी १४ कादिन टेक्सासमा हुने भएको छ। साधारण सभाको उद्घाटन गर्न नेपालबाट परराष्टमन्त्री डा.प्रकाशशरण महत आउने कार्यक्रम रहेको एनआरएन अमेरिकाका अध्यक्ष डा.केशव पौडेलले बताए।\\nअमेरिकामा उम्मेदवारी दिने क्रम शुरु भएको छ। अमेरिकामा सदस्यता वृद्धि भएकोले विधान परिवर्तन गर्नुपर्ने आवाज उठेको छ।\\xa0\\nसाधारणसभामा संगठन विस्तारकालागिअत्याधिक नेपालीलाई सदस्यताका लागि पहल गर्ने, विधान संशोधनको विषय, अमेरिकाको न्यूजर्सीमा सम्पन्न क्षेत्रीय सम्मेलनका क्रममा उठेको एनआरएन भिजन २०२० को कार्यन्वय नगर्ने विषयमाथि छलफल गरिनेछ। आगामी नयाँ नेतृत्व छान्ने अधिवेसनको आधार तय गर्न पनि यो साधारण सभाले महत्व राख्ने छ।\\nजसका लागि यतिखेर अमेरिकामा उम्मेदवारी दिने क्रम शुरु भएको छ। अमेरिकामा सदस्यता वृद्धि भएकोले विधान परिवर्तन गर्नुपर्ने आवाज उठेको छ।\\xa0\\nगैरआवासिय नेपाली संघको एनसिसिहरुमा सबै भन्दा ठूलो अमेरिकामा १० हजार ७ सय साधारण सदस्यहरु छन्। अमेरिकामा रहेका नेपालीहरुको संख्या हिसावले यो पनि कम सदस्य हुन्। अमेरिकामा करिब २ लाख ८० हजार नेपाली छन्।\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RFahX9W9ZYMV",
    "outputId": "1ee654c0-1f2e-415e-e52b-a0962c26b9f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "न्यूयोर्क—गैरआवासिय नेपाली संघ अमेरिकाको पाँचौ साधारणसभा जनवरी १४ कादिन टेक्सासमा हुने भएको छ। साधारण सभाको उद्घाटन गर्न नेपालबाट परराष्टमन्त्री डा.प्रकाशशरण महत आउने कार्यक्रम रहेको एनआरएन अमेरिकाका अध्यक्ष डा.केशव पौडेलले बताए।\n",
      "अमेरिकामा उम्मेदवारी दिने क्रम शुरु भएको छ। अमेरिकामा सदस्यता वृद्धि भएकोले विधान परिवर्तन गर्नुपर्ने आवाज उठेको छ। \n",
      "साधारणसभामा संगठन विस्तारकालागिअत्याधिक नेपालीलाई सदस्यताका लागि पहल गर्ने, विधान संशोधनको विषय, अमेरिकाको न्यूजर्सीमा सम्पन्न क्षेत्रीय सम्मेलनका क्रममा उठेको एनआरएन भिजन २०२० को कार्यन्वय नगर्ने विषयमाथि छलफल गरिनेछ। आगामी नयाँ नेतृत्व छान्ने अधिवेसनको आधार तय गर्न पनि यो साधारण सभाले महत्व राख्ने छ।\n",
      "जसका लागि यतिखेर अमेरिकामा उम्मेदवारी दिने क्रम शुरु भएको छ। अमेरिकामा सदस्यता वृद्धि भएकोले विधान परिवर्तन गर्नुपर्ने आवाज उठेको छ। \n",
      "गैरआवासिय नेपाली संघको एनसिसिहरुमा सबै भन्दा ठूलो अमेरिकामा १० हजार ७ सय साधारण सदस्यहरु छन्। अमेरिकामा रहेका नेपालीहरुको संख्या हिसावले यो पनि कम सदस्य हुन्। अमेरिकामा करिब २ लाख ८० हजार नेपाली छन्।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(texts[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQa0ox85gYW2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoPv-QygganA"
   },
   "source": [
    "# Split texts into the list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNmrlRnuZYKC",
    "outputId": "58e95f3a-36cb-41f0-e426-f31db618ffea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78079\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "##Split in text\n",
    "paragraph = list()\n",
    "for text in texts:\n",
    "    raw = re.split(r\"\\n|\\r\",text.strip())\n",
    "    if len(text) > 0 or not re.match('(\\s)+',text): \n",
    "        paragraph.extend(raw)\n",
    "print(len(paragraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "qw2C9tKcZXlc",
    "outputId": "d297f243-49e3-40e8-8388-0d85390ba875"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'भुवनले छोरा अनमोल केसीको अभिनय रहेको ‘कृ’का लागि आफूले खेलेको लोकप्रिय फिल्म ‘सम्झना’को लोकप्रिय गीतको एक टुक्रा प्रयोग गरेका थिए । ‘कृ’मा रहेको ‘धेरैपछि सम्झना, आँखा छोपी बसन’ बोलको गीतमा ‘उकालीमा अघिअघि’को टुक्रा पुरानै धुनमा समावेश गरिएको छ । अनुमति नै नलिई गीत राखेको भन्दै ‘सम्झना’ फिल्मका निर्देशक शम्भु प्रधान प्रहरी कार्यालय पुगेका हुन् ।\\xa0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ddxdQZrZXgy",
    "outputId": "bac9e1c3-2195-46db-b003-acaa7144c3c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207449\n"
     ]
    }
   ],
   "source": [
    "# Split Into Sentences based on purna biram\n",
    "pura_sents = []\n",
    "for i in paragraph:\n",
    "    pura_sents.extend(re.split(r'(?<=।)\\s',i))\n",
    "print(len(pura_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "roie-F1RZXb-",
    "outputId": "7fee9cc3-442b-4676-bdc4-6c8fe92014c1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'मधुबाला हिन्दी फिल्मकी सर्वकालिक उम्दा नायिकाका रूपमा चिनिन्छिन्।'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pura_sents[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52W8GsBhZ81F",
    "outputId": "92424fbc-f8b3-4db6-ef38-fe438c1094ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211586\n"
     ]
    }
   ],
   "source": [
    "# Split sentence based on question mark\n",
    "purna_prasna_sents = []\n",
    "for i in pura_sents:\n",
    "    purna_prasna_sents.extend(re.split(r'(?<=\\?)\\s',i))\n",
    "#sents\n",
    "print(len(purna_prasna_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caiknAbTZ8wo",
    "outputId": "e11c74d0-99b0-4c20-9017-fee34ad113e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212186\n"
     ]
    }
   ],
   "source": [
    "# Split sentences baseed on exclamation\n",
    "sents = []\n",
    "for i in purna_prasna_sents:\n",
    "    sents.extend(re.split(r'(?<=\\!)\\s',i))\n",
    "#sents\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_CmIZDBjbhTQ",
    "outputId": "53a05b47-14a1-4c33-d45a-1dddd7e2911a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gLs0eXY2bhOS",
    "outputId": "c798558e-4539-47ed-9fb2-f1d8d817dd9b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRUOkAH_cF__",
    "outputId": "bfcb355d-ac84-4d3e-d003-4cfe47bbd5a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2350"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('म')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "6yJel8IWbgiS",
    "outputId": "2294cd27-8431-4968-c8a3-a80817f768a5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'म'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(2350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbASCkh9cZv9"
   },
   "source": [
    "# Removing Non-devanagari letters\n",
    "\n",
    "Devaganari characters has ascii vale from decimal 2304 to 2431 and in hexa 0900 to 097F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3HxbEKQZ8r9"
   },
   "outputs": [],
   "source": [
    "non_dev_nagari = []\n",
    "for i in sents:\n",
    "    for j in i:\n",
    "        #Devanagari range \n",
    "        if not 0x0090 <= ord(j) <= 0x97F: \n",
    "            non_dev_nagari.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqvJP7s5arfU"
   },
   "outputs": [],
   "source": [
    "remove_candidates = set(non_dev_nagari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pcKkXTK8arba",
    "outputId": "ba9c8366-62fd-499f-bb25-e9a696e9099b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '*',\n",
       " '+',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '\\x81',\n",
       " '\\x8d',\n",
       " '১',\n",
       " '\\u200b',\n",
       " '\\u200c',\n",
       " '‐',\n",
       " '—',\n",
       " '„',\n",
       " '•',\n",
       " '…',\n",
       " '\\u2028',\n",
       " '\\u2029',\n",
       " '\\u202f',\n",
       " '‰',\n",
       " '′',\n",
       " '›',\n",
       " '│',\n",
       " '┐',\n",
       " '┬',\n",
       " '╕',\n",
       " '╖',\n",
       " '╛',\n",
       " '╜',\n",
       " '╡',\n",
       " '╢',\n",
       " '╣',\n",
       " '░',\n",
       " '▓',\n",
       " '◊',\n",
       " '☔',\n",
       " '✨',\n",
       " '❤',\n",
       " '⭐',\n",
       " '\\uf02d',\n",
       " '\\uf0a7'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\\u200d is ZWJ\n",
    "#\\xa0 is non breaking space\n",
    "remove_candidates-={\" \",\"!\",\"(\",\")\",\"–\",\"’\",\"‘\",\",\",\".\",\"?\",\"-\",\"/\",\":\",\"“\",\"”\",\"\\u200d\",\"\\xa0\",\"'\"}\n",
    "\n",
    "remove_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZ2XrEz0arXc",
    "outputId": "6d0c549c-f7e6-4991-f958-59ad7b35cddf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1910"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_char_sents = []\n",
    "chr_valid_sents = []\n",
    "for i in sents:\n",
    "    invalid = False\n",
    "    invalid_chars = set()\n",
    "    for j in i:\n",
    "        #Devanagari range \n",
    "        if j in remove_candidates: \n",
    "            invalid = True\n",
    "            invalid_chars.update((j))\n",
    "    if invalid :\n",
    "        invalid_char_sents.append(i+\"**\"+\"*\".join(invalid_chars)) #For filtering\n",
    "    else:\n",
    "        chr_valid_sents.append(i)\n",
    "len(invalid_char_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHcHJQTvarRz"
   },
   "outputs": [],
   "source": [
    "##Remove Puntuation..#I know I should use regex...But it was easir to do it this way :D\n",
    "#(\",\")\",\"–\",\"’\",\"‘\",\",\",\".\",\"?\",\"-\",\"/\",\":\",\"“\",\"”\",\"\\u200d\",\"\\xa0\",\"'\"\n",
    "punct_removed_sents = []\n",
    "for i in chr_valid_sents:\n",
    "    punct_removed_sents.append(i.replace(\"'\",\"\")\n",
    "                              .replace(',',\" \")\n",
    "                                .replace('’',\"\")\n",
    "                               .replace('‘',\"\")\n",
    "                               .replace('–',\" \")\n",
    "                               .replace('\\xa0',\" \")#Space Character \n",
    "                               .replace(\"'\",\"\")\n",
    "                               .replace(\"“\",\"\")\n",
    "                               .replace(\"”\",\"\")\n",
    "                               .replace(\"-\",\"\")\n",
    "                               .replace(\"?\",\"\")\n",
    "                               .replace(\"।\",\"\")\n",
    "                               .replace(\"!\",\"\")\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yqBGRObedlmM",
    "outputId": "2947ec11-9330-494b-b538-3f79806d1c4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210276"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(punct_removed_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tczuUTHndoSe",
    "outputId": "b26bb84a-4baf-4dba-8b59-2eb6ab25865d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(punct_removed_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlmevG4Jgsqx",
    "outputId": "62a85395-a470-4bcd-aae9-dfb27d9dca61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "काठमाडौं   नेपाली साहित्य विकास परिषद युकेका वरिष्ठ सहअध्यक्ष कोमल मल्लको कविता सङ्ग्रह म देश लेख्छु को विमोचन गरिएको छ\n",
      "प्रयोगशाला जोखिम भत्ता\n",
      "श्रवण मुकारुङको बिसे नगर्चीको बयान लोकतन्त्रपछिको सबैभन्दा चर्चित कविता हो\n",
      "घमण्ड गर्ने मेरो संस्कार छँदैछैन र गर्दिन पनि \n"
     ]
    }
   ],
   "source": [
    "print(punct_removed_sents[1000])\n",
    "print(punct_removed_sents[90000])\n",
    "print(punct_removed_sents[3000])\n",
    "print(punct_removed_sents[3400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2mYPGU4eQy7",
    "outputId": "f5e030a1-ec49-4347-cc22-7fcad03b89d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['धादिङ नेपालसहित ११ देशका कलाकारले धादिङ महोत्सवमा प्रस्तुती देखाएका छन्']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the unnecessary spaces and empty sentences\n",
    "def filter(sentences):\n",
    "  return [re.sub(' +', ' ', sentence) for sentence in sentences if len(sentence) > 0]\n",
    "\n",
    "tmp_sentences = ['धादिङ    नेपालसहित ११ देशका कलाकारले धादिङ महोत्सवमा प्रस्तुती देखाएका छन्', '']\n",
    "filter(tmp_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKA1w8cleQs6"
   },
   "outputs": [],
   "source": [
    "filtered_sentences = filter(punct_removed_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZbuDXc_eQkM",
    "outputId": "bdc9b871-b1e3-4f8e-b27a-5419053c8047"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/final_sentences.pkl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(filtered_sentences, \"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/final_sentences.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlvJi7cGfniS"
   },
   "outputs": [],
   "source": [
    "final_sentences = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/final_sentences.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_UU_Dupfv2D",
    "outputId": "b456b338-c160-48b3-a0d3-a5d5081cbe13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "uCoxDqOIft69",
    "outputId": "385a4d8f-71e8-4abb-88c8-f4236257cb3b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'दृश्य खिच्दै गर्दा दिलिपकुमारले मधुबालालाई साँच्चिकै थप्पड हानिदिए'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sentences[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "S6xqJFcigA6q",
    "outputId": "d00aaf81-c82b-49de-abcc-9094d7f94aff"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'२०७२ बैसाख १२ गते गएको भूकम्पमा परेर लाङटाङमा तीन सय भन्दा बढीले ज्यान गुमाएका थिए'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sentences[10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqzEAhIzhgVP"
   },
   "source": [
    "# Removing numbers from the text corpus\n",
    "\n",
    "Ascii value of 0 in devanagari is 2406 i.e unicode hex: U+0966\n",
    "\n",
    "Ascii value of 9 in devanagarai is 2415 i.e unicode hex: U+096F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zbCcg7ISiAKq",
    "outputId": "56bf0b0c-4a4d-48a0-87bb-e326c6ad4b21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2407"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('१')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkrWsqTniv6b"
   },
   "outputs": [],
   "source": [
    "tmp_sent = \"२०७२ बैसाख १२ गते गएको भूकम्पमा परेर लाङटाङमा तीन सय भन्दा बढीले ज्यान गुमाएका थिए\"\n",
    "tmp_sent_1 = \"मकवानपुर फिल्म हुर्रेले रिलिज मिति नजिकिएसँगै प्रचारप्रसारमा तीव्रता दिएको छ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEzTVpH-i11F",
    "outputId": "e4a54932-053f-471f-e21d-fee7a0786cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['२०७२', 'बैसाख', '१२', 'गते', 'गएको', 'भूकम्पमा', 'परेर', 'लाङटाङमा', 'तीन', 'सय', 'भन्दा', 'बढीले', 'ज्यान', 'गुमाएका', 'थिए']\n",
      "['मकवानपुर', 'फिल्म', 'हुर्रेले', 'रिलिज', 'मिति', 'नजिकिएसँगै', 'प्रचारप्रसारमा', 'तीव्रता', 'दिएको', 'छ', '']\n"
     ]
    }
   ],
   "source": [
    "print(tmp_sent.split(\" \"))\n",
    "print(tmp_sent_1.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcXg7OH0lFIC",
    "outputId": "a0d1374b-5477-4a01-cdd0-76e72724d9f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['मकवानपुर',\n",
       " 'फिल्म',\n",
       " 'हुर्रेले',\n",
       " 'रिलिज',\n",
       " 'मिति',\n",
       " 'नजिकिएसँगै',\n",
       " 'प्रचारप्रसारमा',\n",
       " 'तीव्रता',\n",
       " 'दिएको',\n",
       " 'छ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_sent_1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFIOTce0lNbS",
    "outputId": "17d4d034-10d7-49a7-c16d-e74f5c856d4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['२०७२',\n",
       " 'बैसाख',\n",
       " '१२',\n",
       " 'गते',\n",
       " 'गएको',\n",
       " 'भूकम्पमा',\n",
       " 'परेर',\n",
       " 'लाङटाङमा',\n",
       " 'तीन',\n",
       " 'सय',\n",
       " 'भन्दा',\n",
       " 'बढीले',\n",
       " 'ज्यान',\n",
       " 'गुमाएका',\n",
       " 'थिए']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_sent.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "cm07_ZuGksr8",
    "outputId": "0e2fcad0-2e3b-4a80-e68e-ebb25aabe6d3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'मकवानपुर फिल्म हुर्रेले रिलिज मिति नजिकिएसँगै प्रचारप्रसारमा तीव्रता दिएको छ'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(word for word in tmp_sent_1.split() if not 2406 <= ord(word[0]) <= 2415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WPK6OgbHi1yz",
    "outputId": "9a75e3cf-16f5-44f4-cf81-07ca087844c0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'बैसाख गते गएको भूकम्पमा परेर लाङटाङमा तीन सय भन्दा बढीले ज्यान गुमाएका थिए'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(word for word in tmp_sent.split() if not 2406 <= ord(word[0]) <= 2415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Q8hT6VTi1wa"
   },
   "outputs": [],
   "source": [
    "def remove_numbers(sentences):\n",
    "  tmp_sentences = []\n",
    "  for sentence in sentences:\n",
    "    # remove the leading and the trailing spaces and check if first letter of word is a number or not\n",
    "    new_sent = ' '.join(word for word in sentence.split() if not 2406 <= ord(word[0]) <= 2415)\n",
    "    tmp_sentences.append(new_sent)\n",
    "  return tmp_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ek4BOzgDiADg"
   },
   "outputs": [],
   "source": [
    "sent_removed_numbers = remove_numbers(final_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vikyN9OxlipF",
    "outputId": "8be5be4a-7c00-4288-e324-7deb14625985"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_removed_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "hi-TCuTVl0FY",
    "outputId": "e4aa4675-20d1-42fa-b549-7ff78b03774d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'बैसाख गते गएको भूकम्पमा परेर लाङटाङमा तीन सय भन्दा बढीले ज्यान गुमाएका थिए'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_removed_numbers[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gJWJuOVxhfhi",
    "outputId": "204a8f19-728d-420b-de5e-330d7124c18e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'दृश्य खिच्दै गर्दा दिलिपकुमारले मधुबालालाई साँच्चिकै थप्पड हानिदिए'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_removed_numbers[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSaQ2S6Wes7C"
   },
   "source": [
    "# Tokenize the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LOhKR_hzfW18"
   },
   "outputs": [],
   "source": [
    "def tokenize_sentences(sentences):\n",
    "  \"\"\"\n",
    "  convert the sentences list into the tokenized form\n",
    "\n",
    "  Input: sentences\n",
    "  Output: list of tokenized words list of sentences\n",
    "  \"\"\"\n",
    "  tokenized_sentences = []\n",
    "  print(\"Tokenizing sentences...\")\n",
    "  for sentence in tqdm(sentences):\n",
    "    tokenized = nltk.word_tokenize(sentence)\n",
    "    tokenized_sentences.append(tokenized)\n",
    "  \n",
    "  return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzf0iCUZmB4x",
    "outputId": "e4a6d690-5f5d-4a79-d452-faa28126ca52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198000/198000 [00:45<00:00, 4324.74it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentences = tokenize_sentences(sent_removed_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_RsavmaCmQ2C",
    "outputId": "66e22d9a-f7cc-45db-fd13-c89e45c169fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['दृश्य', 'खिच्दै', 'गर्दा', 'दिलिपकुमारले', 'मधुबालालाई', 'साँच्चिकै', 'थप्पड', 'हानिदिए']\n",
      "['बैसाख', 'गते', 'गएको', 'भूकम्पमा', 'परेर', 'लाङटाङमा', 'तीन', 'सय', 'भन्दा', 'बढीले', 'ज्यान', 'गुमाएका', 'थिए']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_sentences[1000])\n",
    "print(tokenized_sentences[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46CW3q5ELNXw",
    "outputId": "299cacdd-8c3d-4952-f524-768e1ec48cf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/tokenized_sentences.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tokenized_sentences, \"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/tokenized_sentences.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJSLY-sPLVyd"
   },
   "outputs": [],
   "source": [
    "tokenized_sentences = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/NLP/Language Modelling/Datasets/Nepali_Corpus/tokenized_sentences.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4M4Nbk-qh40_"
   },
   "source": [
    "# Split into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_d9SCnqqlm6"
   },
   "outputs": [],
   "source": [
    "tokenized_data = tokenized_sentences\n",
    "random.seed(101)\n",
    "random.shuffle(tokenized_data)\n",
    "\n",
    "train_size = int(len(tokenized_data) * 0.9)\n",
    "train_data = tokenized_data[0:train_size]\n",
    "test_data = tokenized_data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uS_KL6hRqlge",
    "outputId": "e3f7842a-b8b5-4106-ab13-2ca9fae0e2d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198000 are split into 178200 train and 19800 test set\n",
      "First Training sample: \n",
      "['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा', 'छैन']\n",
      "First Test Sample: \n",
      "['ना', 'ख', 'नम्बरको', 'बाह्र', 'चक्के', 'ट्रकले', 'पैदल', 'हिँड्दै', 'गरेका', 'सोही', 'ठाउँमा', 'वर्षीय', 'चन्द्रमान', 'श्रेष्ठलाई', 'ठक्कर', 'दिँदा', 'उनको', 'घटनास्थलमै', 'ज्यान', 'गएको', 'ट्राफिक', 'प्रमुख', 'दयाराम', 'पौडेलले', 'बताए']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(tokenized_data)} are split into {len(train_data)} train and {len(test_data)} test set\")\n",
    "\n",
    "print(\"First Training sample: \")\n",
    "print(train_data[0])\n",
    "print(\"First Test Sample: \")\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3aTU0DXqlcm"
   },
   "outputs": [],
   "source": [
    "def count_words(tokenized_sentences):\n",
    "  \"\"\"\n",
    "  Count the number of word appearances in the tokenized sentences\n",
    "  \"\"\"\n",
    "\n",
    "  word_counts = {}\n",
    "  for sentence in tokenized_sentences:\n",
    "    for token in sentence:\n",
    "      if token not in word_counts.keys():\n",
    "        word_counts[token] = 1\n",
    "      else:\n",
    "        word_counts[token] += 1\n",
    "  \n",
    "\n",
    "  return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QrdFqyuwqlUi",
    "outputId": "691eb70a-eee6-4df6-beef-b7e965aade5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sky': 1,\n",
       " 'is': 1,\n",
       " 'blue': 1,\n",
       " '.': 3,\n",
       " 'leaves': 1,\n",
       " 'are': 2,\n",
       " 'green': 1,\n",
       " 'roses': 1,\n",
       " 'red': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences = [['sky', 'is', 'blue', '.'],\n",
    "                       ['leaves', 'are', 'green', '.'],\n",
    "                       ['roses', 'are', 'red', '.']]\n",
    "count_words(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eg7UrTzesG5A"
   },
   "source": [
    "# Handling OUt of Vocabulary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qSgQuzgr7wk"
   },
   "outputs": [],
   "source": [
    "def get_words_with_nplus_frequency(tokenized_sentences, count_threshold):\n",
    "  closed_vocab = []\n",
    "\n",
    "  word_counts = count_words(tokenized_sentences)\n",
    "\n",
    "  for word, cnt in word_counts.items():\n",
    "    if cnt >= count_threshold:\n",
    "      closed_vocab.append(word)\n",
    "  \n",
    "  return closed_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bd3QJpBHsbkR",
    "outputId": "7902457c-99de-444d-fd9f-a521b6d29ddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed vocabulary:\n",
      "['.', 'are']\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentences = [['sky', 'is', 'blue', '.'],\n",
    "                       ['leaves', 'are', 'green', '.'],\n",
    "                       ['roses', 'are', 'red', '.']]\n",
    "tmp_closed_vocab = get_words_with_nplus_frequency(tokenized_sentences, count_threshold=2)\n",
    "print(f\"Closed vocabulary:\")\n",
    "print(tmp_closed_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQY9_4wNseqc"
   },
   "outputs": [],
   "source": [
    "def replace_oov_words_by_unk(tokenized_sentences, vocabulary, unknown_token = \"<unk>\"):\n",
    "  \"\"\"\n",
    "  Replaced all the words in tokenized_sentences not in vocabulary by the unknown_token\n",
    "  \"\"\"\n",
    "  \n",
    "  vocabulary = set(vocabulary)\n",
    "\n",
    "  replaced_tokenized_sentences = []\n",
    "\n",
    "  for sentence in tokenized_sentences:\n",
    "    replaced_sentence = []\n",
    "\n",
    "    for token in sentence:\n",
    "      if token in vocabulary:\n",
    "        replaced_sentence.append(token)\n",
    "      else:\n",
    "        replaced_sentence.append(unknown_token)\n",
    "    replaced_tokenized_sentences.append(replaced_sentence)\n",
    "  \n",
    "  return replaced_tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRZbuRtwtG7D",
    "outputId": "23add9b1-14ba-4650-a893-5da9926deded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence:\n",
      "[['dogs', 'run'], ['cats', 'sleep']]\n",
      "tokenized_sentences with less frequent words converted to '<unk>':\n",
      "[['dogs', '<unk>'], ['<unk>', 'sleep']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentences = [[\"dogs\", \"run\"], [\"cats\", \"sleep\"]]\n",
    "vocabulary = [\"dogs\", \"sleep\"]\n",
    "tmp_replaced_tokenized_sentences = replace_oov_words_by_unk(tokenized_sentences, vocabulary)\n",
    "\n",
    "print(f\"Original sentence:\")\n",
    "print(tokenized_sentences)\n",
    "print(f\"tokenized_sentences with less frequent words converted to '<unk>':\")\n",
    "print(tmp_replaced_tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcOON2SLtKEI"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data, count_threshold):\n",
    "  vocabulary = get_words_with_nplus_frequency(train_data, count_threshold)\n",
    "\n",
    "  train_data_replaced = replace_oov_words_by_unk(train_data, vocabulary)\n",
    "\n",
    "  test_data_replaced = replace_oov_words_by_unk(test_data, vocabulary)\n",
    "\n",
    "  return train_data_replaced, test_data_replaced, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSFqO4L2tPMk",
    "outputId": "8a6fad3d-240d-4469-89ff-6fdc533459af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_train_repl\n",
      "[['sky', 'is', 'blue', '.'], ['leaves', 'are', 'green']]\n",
      "\n",
      "tmp_test_repl\n",
      "[['<unk>', 'are', '<unk>', '.']]\n",
      "\n",
      "tmp_vocab\n",
      "['sky', 'is', 'blue', '.', 'leaves', 'are', 'green']\n"
     ]
    }
   ],
   "source": [
    "tmp_train = [['sky', 'is', 'blue', '.'], ['leaves', 'are', 'green']]\n",
    "tmp_test = [['roses', 'are', 'red', '.']]\n",
    "\n",
    "tmp_train_repl, tmp_test_repl, tmp_vocab = preprocess_data(tmp_train, tmp_test, count_threshold = 1)\n",
    "\n",
    "print(\"tmp_train_repl\")\n",
    "print(tmp_train_repl)\n",
    "print()\n",
    "print(\"tmp_test_repl\")\n",
    "print(tmp_test_repl)\n",
    "print()\n",
    "print(\"tmp_vocab\")\n",
    "print(tmp_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wdqsrGptv9c"
   },
   "outputs": [],
   "source": [
    "minimum_freq = 2\n",
    "train_data_processed, test_data_processed, vocabulary = preprocess_data(train_data, test_data, minimum_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsPJp1gzt-2U",
    "outputId": "f0c189d6-10dd-4f37-e441-14fb6c4fec58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First preprocessed training sample:\n",
      "Original Sentence :  ['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा', 'छैन']\n",
      "['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा', 'छैन']\n",
      "\n",
      "First preprocessed test sample:\n",
      "Original Sentence :  ['ना', 'ख', 'नम्बरको', 'बाह्र', 'चक्के', 'ट्रकले', 'पैदल', 'हिँड्दै', 'गरेका', 'सोही', 'ठाउँमा', 'वर्षीय', 'चन्द्रमान', 'श्रेष्ठलाई', 'ठक्कर', 'दिँदा', 'उनको', 'घटनास्थलमै', 'ज्यान', 'गएको', 'ट्राफिक', 'प्रमुख', 'दयाराम', 'पौडेलले', 'बताए']\n",
      "['ना', 'ख', 'नम्बरको', 'बाह्र', '<unk>', 'ट्रकले', 'पैदल', 'हिँड्दै', 'गरेका', 'सोही', 'ठाउँमा', 'वर्षीय', 'चन्द्रमान', 'श्रेष्ठलाई', 'ठक्कर', 'दिँदा', 'उनको', 'घटनास्थलमै', 'ज्यान', 'गएको', 'ट्राफिक', 'प्रमुख', 'दयाराम', 'पौडेलले', 'बताए']\n",
      "\n",
      "First 10 vocabulary:\n",
      "['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा', 'छैन', 'धेरै', 'कारोबार', 'कार्डबाट', 'हुने']\n",
      "\n",
      "Size of vocabulary: 80552\n"
     ]
    }
   ],
   "source": [
    "print(\"First preprocessed training sample:\")\n",
    "print(\"Original Sentence : \", train_data[0])\n",
    "print(train_data_processed[0])\n",
    "print()\n",
    "print(\"First preprocessed test sample:\")\n",
    "print(\"Original Sentence : \", test_data[0])\n",
    "print(test_data_processed[0])\n",
    "print()\n",
    "print(\"First 10 vocabulary:\")\n",
    "print(vocabulary[0:10])\n",
    "print()\n",
    "print(\"Size of vocabulary:\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12VIMFqHumB8"
   },
   "source": [
    "# Develop a n gram based language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F0fvrJ3JuDGq"
   },
   "outputs": [],
   "source": [
    "def count_n_grams(data, n, start_token = \"<s>\", end_token = \"</s>\"):\n",
    "  \"\"\"\n",
    "  Count all the n-grams of the data\n",
    "  \"\"\"\n",
    "\n",
    "  n_grams = {}\n",
    "\n",
    "  for sentence in data:\n",
    "    # prepend start token n times and append end token one time\n",
    "    sentence = [start_token] * n + sentence + [end_token]\n",
    "\n",
    "    # convert list to tuple so that the sequence of words can be used as a key in the dictionary\n",
    "    sentence = tuple(sentence)\n",
    "\n",
    "    # use value of m to denote the number of n grams in the current sentence\n",
    "    m = len(sentence) if n==1 else len(sentence) - 1\n",
    "\n",
    "    for i in range(m):\n",
    "      n_gram = sentence[i: i + n]\n",
    "\n",
    "      # check if the n-gram is in the dictionary\n",
    "      # if present, increase the value else se the value of n-gram to 1\n",
    "      if n_gram in n_grams.keys():\n",
    "        n_grams[n_gram] += 1\n",
    "      else:\n",
    "        n_grams[n_gram] = 1\n",
    "\n",
    "  return n_grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CobVz4nsvhLH",
    "outputId": "1f795b8f-5546-46f3-f0ab-b0ced4f7c0bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uni-gram:\n",
      "{('<s>',): 2, ('i',): 1, ('like',): 2, ('a',): 2, ('cat',): 2, ('</s>',): 2, ('this',): 1, ('dog',): 1, ('is',): 1}\n",
      "Bi-gram:\n",
      "{('<s>', '<s>'): 2, ('<s>', 'i'): 1, ('i', 'like'): 1, ('like', 'a'): 2, ('a', 'cat'): 2, ('cat', '</s>'): 2, ('<s>', 'this'): 1, ('this', 'dog'): 1, ('dog', 'is'): 1, ('is', 'like'): 1}\n"
     ]
    }
   ],
   "source": [
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "print(\"Uni-gram:\")\n",
    "print(count_n_grams(sentences, 1))\n",
    "print(\"Bi-gram:\")\n",
    "print(count_n_grams(sentences, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oa3s4078T_vH"
   },
   "outputs": [],
   "source": [
    "def estimate_probability(word, previous_n_gram, n_gram_counts, n_plus1_gram_counts, vocabulary_size, k = 1.0):\n",
    "  \"\"\"\n",
    "  Estimate the probabilities of the next word using the n-gram counts with k-smoothing\n",
    "  \"\"\"\n",
    "\n",
    "  # convert the list to tuple to use it as a dictionary key\n",
    "  previous_n_gram = tuple(previous_n_gram)\n",
    "\n",
    "  # set the denominator\n",
    "  # if the previous n-gram exists in the dictionary of n-gram counts, get its coun\n",
    "  # else set the count to zero\n",
    "  # use the dictionary that has counts for n-grams\n",
    "  previous_n_gram_count = n_gram_counts[previous_n_gram] if previous_n_gram in n_gram_counts else 0\n",
    "\n",
    "  # calculate the denominator useing the count fo the previous n gram and apply k-smoothing\n",
    "  denominator = previous_n_gram_count + k * vocabulary_size\n",
    "\n",
    "  # define n plus 1 gram as the previous n-gram plus the current word as a tuple\n",
    "  n_plus1_gram = previous_n_gram + (word, )\n",
    "\n",
    "  # set the count to the count in the dictionary\n",
    "  # 0 if not in the dictionary\n",
    "  # use the dictionary that has counts for the n-gram plus current word\n",
    "  n_plus1_gram_count = n_plus1_gram_counts[n_plus1_gram] if n_plus1_gram in n_plus1_gram_counts else 0\n",
    "\n",
    "  # define the numerator using the counf of the n-gram plus current word and apply smoothing\n",
    "  numerator = n_plus1_gram_count + k\n",
    "\n",
    "  # calculate the probability as the numberator divided by the denominator\n",
    "  probability = numerator / denominator\n",
    "\n",
    "  return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzDJJatcvvAO",
    "outputId": "d6090041-e4cc-4064-d5cd-e4f1f59e3c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated probability of word 'cat' given the previous n-gram 'a' is: 0.3333\n"
     ]
    }
   ],
   "source": [
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "unique_words = list(set(sentences[0] + sentences[1]))\n",
    "\n",
    "unigram_counts = count_n_grams(sentences, 1)\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "tmp_prob = estimate_probability(\"cat\", \"a\", unigram_counts, bigram_counts, len(unique_words), k=1)\n",
    "\n",
    "print(f\"The estimated probability of word 'cat' given the previous n-gram 'a' is: {tmp_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZhLvo34Uv4OP"
   },
   "outputs": [],
   "source": [
    "def estimate_probabilities(previous_n_gram, n_gram_counts, n_plus1_gram_counts, vocabulary, k = 1.0):\n",
    "  \"\"\"\n",
    "  Estimate the probabilities of next words using the n-gram counts with k-smoothing\n",
    "  \"\"\"\n",
    "  # convert the list to tuple to use it as a dictionary key\n",
    "  previous_n_gram = tuple(previous_n_gram)\n",
    "\n",
    "  # add </s> and <unk> to the vocabulary\n",
    "  # <s> is not needed as it should not appear as the next word\n",
    "  vocabulary = vocabulary + [\"</s>\", \"<unk>\"]\n",
    "  vocabular_size = len(vocabulary)\n",
    "\n",
    "  probabilities = {}\n",
    "  for word in vocabulary:\n",
    "    probability = estimate_probability(word, previous_n_gram, n_gram_counts, n_plus1_gram_counts, vocabular_size, k = k)\n",
    "    probabilities[word] = probability\n",
    "  \n",
    "  return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1JqAK3uwJm5",
    "outputId": "d9fe75f3-cf75-4e3d-b58e-36cab25571de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0.2727272727272727,\n",
       " 'dog': 0.09090909090909091,\n",
       " 'is': 0.09090909090909091,\n",
       " 'this': 0.09090909090909091,\n",
       " 'a': 0.09090909090909091,\n",
       " 'like': 0.09090909090909091,\n",
       " 'i': 0.09090909090909091,\n",
       " '</s>': 0.09090909090909091,\n",
       " '<unk>': 0.09090909090909091}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "unique_words = list(set(sentences[0] + sentences[1]))\n",
    "unigram_counts = count_n_grams(sentences, 1)\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "estimate_probabilities(\"a\", unigram_counts, bigram_counts, unique_words, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0f6bJchwfXP"
   },
   "source": [
    "# Count and Probability matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80-QqKDcwNBo"
   },
   "outputs": [],
   "source": [
    "def make_count_matrix(n_plus1_gram_counts, vocabulary):\n",
    "  # add </s> and <UNK> to the vocabulary\n",
    "  # <s> is omitted since it should not appear as next word\n",
    "  vocabulary = vocabulary + [\"</s>\", \"<UNK>\"]\n",
    "\n",
    "  # obtain unique n-grams from n_plus1_gram_counts\n",
    "  n_grams = []\n",
    "  for n_plus1_gram in n_plus1_gram_counts.keys():\n",
    "    # n_gram is from first to second last words of n_plus1_gram\n",
    "    n_gram = n_plus1_gram[0:-1]\n",
    "    n_grams.append(n_gram)\n",
    "  n_grams = list(set(n_grams))\n",
    "\n",
    "  # mapping from n-gram to row\n",
    "  row_index = {n_gram : i for i, n_gram in enumerate(n_grams)}\n",
    "\n",
    "  # mapping from next word to column\n",
    "  col_index = {word : j for j, word in enumerate(vocabulary)}\n",
    "\n",
    "  # No. of rows = No. of n_grams\n",
    "  # No. of columns = No. of vocabulary\n",
    "  nrow = len(n_grams)\n",
    "  ncol = len(vocabulary)\n",
    "\n",
    "  # Initialize the count matrix of zeros with nrow and ncol\n",
    "  count_matrix = np.zeros((nrow, ncol))\n",
    "\n",
    "  # creating a count matrix from n_plus1_gram_counts\n",
    "  for n_plus1_gram, count in n_plus1_gram_counts.items():\n",
    "    n_gram = n_plus1_gram[0:-1]\n",
    "    word = n_plus1_gram[-1]\n",
    "    if word not in vocabulary:\n",
    "      continue\n",
    "    i = row_index[n_gram]\n",
    "    j = col_index[word]\n",
    "    count_matrix[i, j] = count\n",
    "\n",
    "  # Creating dataframe of count matrix\n",
    "  count_matrix = pd.DataFrame(count_matrix, index = n_grams, columns = vocabulary)\n",
    "\n",
    "  return count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "vIlS4XtwwjjO",
    "outputId": "66990a90-dedf-4689-9a86-f1bc6a4f0df2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram counts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0376a9f8-29ac-46d2-9e2c-cb5e6a0e0b18\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>is</th>\n",
       "      <th>this</th>\n",
       "      <th>a</th>\n",
       "      <th>like</th>\n",
       "      <th>i</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <th>&lt;UNK&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(cat,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(dog,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(is,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(this,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(a,)</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(&lt;s&gt;,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(like,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0376a9f8-29ac-46d2-9e2c-cb5e6a0e0b18')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0376a9f8-29ac-46d2-9e2c-cb5e6a0e0b18 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0376a9f8-29ac-46d2-9e2c-cb5e6a0e0b18');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         cat  dog   is  this    a  like    i  </s>  <UNK>\n",
       "(cat,)   0.0  0.0  0.0   0.0  0.0   0.0  0.0   2.0    0.0\n",
       "(i,)     0.0  0.0  0.0   0.0  0.0   1.0  0.0   0.0    0.0\n",
       "(dog,)   0.0  0.0  1.0   0.0  0.0   0.0  0.0   0.0    0.0\n",
       "(is,)    0.0  0.0  0.0   0.0  0.0   1.0  0.0   0.0    0.0\n",
       "(this,)  0.0  1.0  0.0   0.0  0.0   0.0  0.0   0.0    0.0\n",
       "(a,)     2.0  0.0  0.0   0.0  0.0   0.0  0.0   0.0    0.0\n",
       "(<s>,)   0.0  0.0  0.0   1.0  0.0   0.0  1.0   0.0    0.0\n",
       "(like,)  0.0  0.0  0.0   0.0  2.0   0.0  0.0   0.0    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = [['i', 'like', 'a', 'cat'], ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "unique_words = list(set(sentences[0] + sentences[1]))\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "\n",
    "print('bigram counts')\n",
    "display(make_count_matrix(bigram_counts, unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyyknZH7wmwa"
   },
   "outputs": [],
   "source": [
    "def make_probability_matrix(n_plus1_gram_counts, vocabulary, k):\n",
    "  count_matrix = make_count_matrix(n_plus1_gram_counts, vocabulary)\n",
    "  # constant is added to each value in count_matrix to make its probability non-zero\n",
    "  count_matrix += k \n",
    "  prob_matrix = count_matrix.div(count_matrix.sum(axis = 1), axis = 0)\n",
    "  return prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "2H2dMVYvxUzR",
    "outputId": "1627721c-0e89-4459-ea47-3a126037a22a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram probabilities\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-dbb19916-a5f4-4210-ad86-59d18292ee7e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>is</th>\n",
       "      <th>this</th>\n",
       "      <th>a</th>\n",
       "      <th>like</th>\n",
       "      <th>i</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <th>&lt;UNK&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(cat,)</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i,)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(dog,)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(is,)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(this,)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(a,)</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(&lt;s&gt;,)</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(like,)</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbb19916-a5f4-4210-ad86-59d18292ee7e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-dbb19916-a5f4-4210-ad86-59d18292ee7e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-dbb19916-a5f4-4210-ad86-59d18292ee7e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "              cat       dog        is      this         a      like         i  \\\n",
       "(cat,)   0.090909  0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
       "(i,)     0.100000  0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
       "(dog,)   0.100000  0.100000  0.200000  0.100000  0.100000  0.100000  0.100000   \n",
       "(is,)    0.100000  0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
       "(this,)  0.100000  0.200000  0.100000  0.100000  0.100000  0.100000  0.100000   \n",
       "(a,)     0.272727  0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
       "(<s>,)   0.090909  0.090909  0.090909  0.181818  0.090909  0.090909  0.181818   \n",
       "(like,)  0.090909  0.090909  0.090909  0.090909  0.272727  0.090909  0.090909   \n",
       "\n",
       "             </s>     <UNK>  \n",
       "(cat,)   0.272727  0.090909  \n",
       "(i,)     0.100000  0.100000  \n",
       "(dog,)   0.100000  0.100000  \n",
       "(is,)    0.100000  0.100000  \n",
       "(this,)  0.100000  0.100000  \n",
       "(a,)     0.090909  0.090909  \n",
       "(<s>,)   0.090909  0.090909  \n",
       "(like,)  0.090909  0.090909  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = [['i', 'like', 'a', 'cat'], ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "unique_words = list(set(sentences[0] + sentences[1]))\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "print(\"bigram probabilities\")\n",
    "display(make_probability_matrix(bigram_counts, unique_words, k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "uDEZHwQUxYBg",
    "outputId": "bdea2058-40c3-498b-c359-4793e1baff4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram probabilities\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f8e78d7b-2eac-4e01-afd4-f23834f25555\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>is</th>\n",
       "      <th>this</th>\n",
       "      <th>a</th>\n",
       "      <th>like</th>\n",
       "      <th>i</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <th>&lt;UNK&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(a, cat)</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(&lt;s&gt;, i)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(cat,)</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(this, dog)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(&lt;s&gt;, this)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, like)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(is, like)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(&lt;s&gt;, &lt;s&gt;)</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(dog, is)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(like, a)</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8e78d7b-2eac-4e01-afd4-f23834f25555')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f8e78d7b-2eac-4e01-afd4-f23834f25555 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f8e78d7b-2eac-4e01-afd4-f23834f25555');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                  cat       dog        is      this         a      like  \\\n",
       "(a, cat)     0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
       "(<s>, i)     0.100000  0.100000  0.100000  0.100000  0.100000  0.200000   \n",
       "(cat,)       0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
       "(this, dog)  0.100000  0.100000  0.200000  0.100000  0.100000  0.100000   \n",
       "(<s>, this)  0.100000  0.200000  0.100000  0.100000  0.100000  0.100000   \n",
       "(i, like)    0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
       "(is, like)   0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
       "(<s>, <s>)   0.090909  0.090909  0.090909  0.181818  0.090909  0.090909   \n",
       "(dog, is)    0.100000  0.100000  0.100000  0.100000  0.100000  0.200000   \n",
       "(like, a)    0.272727  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
       "\n",
       "                    i      </s>     <UNK>  \n",
       "(a, cat)     0.090909  0.272727  0.090909  \n",
       "(<s>, i)     0.100000  0.100000  0.100000  \n",
       "(cat,)       0.090909  0.272727  0.090909  \n",
       "(this, dog)  0.100000  0.100000  0.100000  \n",
       "(<s>, this)  0.100000  0.100000  0.100000  \n",
       "(i, like)    0.100000  0.100000  0.100000  \n",
       "(is, like)   0.100000  0.100000  0.100000  \n",
       "(<s>, <s>)   0.181818  0.090909  0.090909  \n",
       "(dog, is)    0.100000  0.100000  0.100000  \n",
       "(like, a)    0.090909  0.090909  0.090909  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"trigram probabilities\")\n",
    "trigram_counts = count_n_grams(sentences, 3)\n",
    "display(make_probability_matrix(trigram_counts, unique_words, k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9tg776Ky1J4"
   },
   "outputs": [],
   "source": [
    "def suggest_a_word(previous_tokens, n_gram_counts, n_plus1_gram_counts, vocabulary, k = 1.0, start_with = None):\n",
    "  \"\"\"\n",
    "  Get suggestion for the next word\n",
    "  \"\"\"\n",
    "\n",
    "  # length of previous words\n",
    "  n = len(list(n_gram_counts.keys())[0])\n",
    "\n",
    "  # From the words that the user already typed, get the most recent 'n' words as the previous n-gram\n",
    "  previous_n_gram = previous_tokens[-n:]\n",
    "\n",
    "  # Estimate the probabilities that each word in the vocabular is the next word\n",
    "  probabilities = estimate_probabilities(previous_n_gram, n_gram_counts, n_plus1_gram_counts, vocabulary, k = k)\n",
    "  \n",
    "  # Words with highest probability will be set to suggestion\n",
    "  suggestion = None\n",
    "\n",
    "  # Initialie the value for maximum probability\n",
    "  max_prob = 0\n",
    "\n",
    "  # For each word and its probability in the probabilities dictionary\n",
    "  for word, prob in probabilities.items():\n",
    "    # if the optional start with string is set\n",
    "    if start_with != None:\n",
    "      # Check if the beginning of word does not match with the letters in 'start_with'\n",
    "      if not word.startswith(start_with):\n",
    "        # if they don't match, skip this word and move onto the next word\n",
    "        continue\n",
    "\n",
    "    # Check if this word's probability is greater than the current maximum probability\n",
    "    if prob > max_prob:\n",
    "      # if so, save this word for the best suggestion\n",
    "      suggestion = word\n",
    "      max_prob = prob\n",
    "  \n",
    "  return suggestion, max_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P___9HsQzGDG",
    "outputId": "3b3e9c9c-5cd0-4139-95e5-2e1ad2cd724c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous words are 'i like',\n",
      "\tand the suggested word is `a` with a probability of 0.2727\n",
      "\n",
      "The previous words are 'i like', the suggestion must start with `c`\n",
      "\tand the suggested word is `cat` with a probability of 0.0909\n"
     ]
    }
   ],
   "source": [
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "unique_words = list(set(sentences[0] + sentences[1]))\n",
    "\n",
    "unigram_counts = count_n_grams(sentences, 1)\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "\n",
    "previous_tokens = [\"i\", \"like\"]\n",
    "tmp_suggest1 = suggest_a_word(previous_tokens, unigram_counts, bigram_counts, unique_words, k=1.0)\n",
    "print(f\"The previous words are 'i like',\\n\\tand the suggested word is `{tmp_suggest1[0]}` with a probability of {tmp_suggest1[1]:.4f}\")\n",
    "\n",
    "print()\n",
    "# test your code when setting the starts_with\n",
    "tmp_starts_with = 'c'\n",
    "tmp_suggest2 = suggest_a_word(previous_tokens, unigram_counts, bigram_counts, unique_words, k=1.0, start_with=tmp_starts_with)\n",
    "print(f\"The previous words are 'i like', the suggestion must start with `{tmp_starts_with}`\\n\\tand the suggested word is `{tmp_suggest2[0]}` with a probability of {tmp_suggest2[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OteHXY1pzMOD"
   },
   "outputs": [],
   "source": [
    "def get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k = 1.0, start_with = None):\n",
    "  # different model means different n_gram\n",
    "  model_counts = len(n_gram_counts_list)\n",
    "  suggestions = []\n",
    "\n",
    "  for i in range(model_counts - 1):\n",
    "    n_gram_counts = n_gram_counts_list[i]\n",
    "    n_plus1_gram_counts = n_gram_counts_list[i + 1]\n",
    "\n",
    "    suggestion = suggest_a_word(previous_tokens, n_gram_counts, n_plus1_gram_counts, vocabulary, k = k, start_with = start_with)\n",
    "\n",
    "    suggestions.append(suggestion)\n",
    "\n",
    "  return suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "InoMLQ7EzTn_",
    "outputId": "d83b7f48-ea71-4c4e-ed2b-8f5fcb5f21dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous words are 'i like', the suggestions are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('a', 0.2727272727272727),\n",
       " ('a', 0.2),\n",
       " ('cat', 0.1111111111111111),\n",
       " ('cat', 0.1111111111111111)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "unique_words = list(set(sentences[0] + sentences[1]))\n",
    "\n",
    "unigram_counts = count_n_grams(sentences, 1)\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "trigram_counts = count_n_grams(sentences, 3)\n",
    "quadgram_counts = count_n_grams(sentences, 4)\n",
    "qintgram_counts = count_n_grams(sentences, 5)\n",
    "\n",
    "n_gram_counts_list = [unigram_counts, bigram_counts, trigram_counts, quadgram_counts, qintgram_counts]\n",
    "previous_tokens = [\"i\", \"like\"]\n",
    "tmp_suggest3 = get_suggestions(previous_tokens, n_gram_counts_list, unique_words, k=1.0)\n",
    "\n",
    "print(f\"The previous words are 'i like', the suggestions are:\")\n",
    "display(tmp_suggest3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "EvlEfCuBzWGI",
    "outputId": "5bb5ecf0-50d1-4804-8542-e35fc95fff2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-de776a97-54d2-4710-8d4b-b6e52b19edb2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>is</th>\n",
       "      <th>this</th>\n",
       "      <th>a</th>\n",
       "      <th>like</th>\n",
       "      <th>i</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <th>&lt;UNK&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(cat,)</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i,)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(dog,)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(is,)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(this,)</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(a,)</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(&lt;s&gt;,)</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(like,)</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de776a97-54d2-4710-8d4b-b6e52b19edb2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-de776a97-54d2-4710-8d4b-b6e52b19edb2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-de776a97-54d2-4710-8d4b-b6e52b19edb2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "              cat       dog        is      this         a      like         i  \\\n",
       "(cat,)   0.090909  0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
       "(i,)     0.100000  0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
       "(dog,)   0.100000  0.100000  0.200000  0.100000  0.100000  0.100000  0.100000   \n",
       "(is,)    0.100000  0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
       "(this,)  0.100000  0.200000  0.100000  0.100000  0.100000  0.100000  0.100000   \n",
       "(a,)     0.272727  0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
       "(<s>,)   0.090909  0.090909  0.090909  0.181818  0.090909  0.090909  0.181818   \n",
       "(like,)  0.090909  0.090909  0.090909  0.090909  0.272727  0.090909  0.090909   \n",
       "\n",
       "             </s>     <UNK>  \n",
       "(cat,)   0.272727  0.090909  \n",
       "(i,)     0.100000  0.100000  \n",
       "(dog,)   0.100000  0.100000  \n",
       "(is,)    0.100000  0.100000  \n",
       "(this,)  0.100000  0.100000  \n",
       "(a,)     0.090909  0.090909  \n",
       "(<s>,)   0.090909  0.090909  \n",
       "(like,)  0.090909  0.090909  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking above suggestions manually\n",
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "unigram_counts = count_n_grams(sentences, 1)\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "trigram_counts = count_n_grams(sentences, 3)\n",
    "quadgram_counts = count_n_grams(sentences, 4)\n",
    "qintgram_counts = count_n_grams(sentences, 5)\n",
    "\n",
    "display(make_probability_matrix(bigram_counts, unique_words, k=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuuakdbz0UXj"
   },
   "source": [
    "# Suggest multiple words using n-gram of varying length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJMQn_6n0mUr",
    "outputId": "fd0b957a-6eae-44b0-81e3-92f4d554afb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा', 'छैन']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9aF339xz786",
    "outputId": "02c37ffb-061e-4ded-9e88-cbd9cae30f72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing n-gram counts with n =  1 ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:02<00:10,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing n-gram counts with n =  2 ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:06<00:09,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing n-gram counts with n =  3 ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:09<00:06,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing n-gram counts with n =  4 ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:12<00:03,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing n-gram counts with n =  5 ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.19s/it]\n"
     ]
    }
   ],
   "source": [
    "n_gram_counts_list = []\n",
    "for n in tqdm(range(1, 6)):\n",
    "  print(\"computing n-gram counts with n = \", n, \"....\")\n",
    "  n_model_counts = count_n_grams(train_data_processed, n)\n",
    "  n_gram_counts_list.append(n_model_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LHinY0iAJM2C",
    "outputId": "e0a8f553-2d7a-4bbd-cf45-75e52fdca448"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "O6jecFAO0uLc",
    "outputId": "f1c67c5d-91a3-44c9-e74f-2a95ba39e443"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous words are ['दरबारमार्गमा', 'शोरुम'], the suggestions are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('खोलेको', 2.482744922786633e-05),\n",
       " ('ऐलानी', 1.2414032822702784e-05),\n",
       " ('ऐलानी', 1.2414032822702784e-05),\n",
       " ('ऐलानी', 1.2414032822702784e-05)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "previous_tokens = ['दरबारमार्गमा', 'शोरुम']\n",
    "tmp_suggest4 = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0)\n",
    "\n",
    "print(f\"The previous words are {previous_tokens}, the suggestions are:\")\n",
    "display(tmp_suggest4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tu23ra8809AY",
    "outputId": "8389cc5e-e641-4c71-9535-417eb6b1d182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ना', 'ख', 'नम्बरको', 'बाह्र', 'चक्के', 'ट्रकले', 'पैदल', 'हिँड्दै', 'गरेका', 'सोही', 'ठाउँमा', 'वर्षीय', 'चन्द्रमान', 'श्रेष्ठलाई', 'ठक्कर', 'दिँदा', 'उनको', 'घटनास्थलमै', 'ज्यान', 'गएको', 'ट्राफिक', 'प्रमुख', 'दयाराम', 'पौडेलले', 'बताए']\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OtCNjbTVHwSe",
    "outputId": "c69c31bd-e907-46a6-af8e-572051f67823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा', 'छैन'], ['धेरै', 'कारोबार', 'क्रेडिट÷डेबिट', 'कार्डबाट', 'हुने', 'हुँदा', 'यसको', 'सुरक्षण', 'प्रणाली', 'दरिलो', 'नभएमा', 'ठगी', 'र', 'अपचलन', 'रहन', 'सक्छ'], ['फलस्वरुप', 'पुनर्निर्माण', 'प्राविधिक', 'र', 'व्यापारिक', 'माखेसाङ्लोमा', 'जकडिन', 'पुग्यो'], ['उपहार', 'पार्सल', 'गरी', 'पठाएको', 'जानकारी', 'दिएर', 'बिदामा', 'बसेका', 'ती', 'युवा', 'उनले', 'रकम', 'पठाएको', 'भोलिपल्टबाटै', 'सामाजिक', 'सञ्जालबाट', 'हराए'], ['आर्थिक', 'समृद्धिको', 'अर्को', 'आधारका', 'रुपमा', 'रहेको', 'ऊर्जा', 'क्षेत्रमा', 'समेत', 'लगानीको', 'मात्रा', 'बढेको', 'विभागले', 'जनाएको', 'छ']]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "HrtbctWfGms9",
    "outputId": "37bf5f7e-aec1-448a-b359-b370690eeaa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous words are ['ऊर्जा'], the suggestions are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('</s>', 0.0063799731369552125),\n",
       " ('<unk>', 7.44130669345537e-05),\n",
       " ('ऐलानी', 1.2414032822702784e-05),\n",
       " ('ऐलानी', 1.2414032822702784e-05)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "previous_tokens = ['ऊर्जा']\n",
    "suggestions = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0)\n",
    "\n",
    "print(f\"The previous words are {previous_tokens}, the suggestions are:\")\n",
    "display(tmp_suggest4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "1xYDo6VT1JrW",
    "outputId": "d34b9c38-85f4-40aa-9008-e5861326f945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous words are ['त्यो', 'त'], the suggestions are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('</s>', 0.0063799731369552125),\n",
       " ('<unk>', 7.44130669345537e-05),\n",
       " ('ऐलानी', 1.2414032822702784e-05),\n",
       " ('ऐलानी', 1.2414032822702784e-05)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "previous_tokens = ['त्यो', 'त']\n",
    "tmp_suggest4 = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0)\n",
    "\n",
    "print(f\"The previous words are {previous_tokens}, the suggestions are:\")\n",
    "display(tmp_suggest4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HSJnEPVD-xy"
   },
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsOKHO4EDv3f"
   },
   "outputs": [],
   "source": [
    "def calculate_perplexity(sentence, n_gram_counts, n_plus1_gram_counts, vocabulary_size, k = 1.0):\n",
    "  \"\"\"\n",
    "  calculate the perplexity for a list of sentences\n",
    "  \"\"\"\n",
    "  # length of previous words\n",
    "  n = len(list(n_gram_counts.keys())[0])\n",
    "\n",
    "  # prepend <s> and append </s>\n",
    "  sentence = [\"<s>\"] * n + sentence + [\"</s>\"]\n",
    "\n",
    "  # cast the sentence from a list to a tuple\n",
    "  sentence = tuple(sentence)\n",
    "\n",
    "  # length of sentence (after adding)\n",
    "  N = len(sentence)\n",
    "\n",
    "  # The variable p will hold hte product that is calculated inside the n-root \n",
    "  # Update this in the code below\n",
    "  product_pi = 1.0\n",
    "\n",
    "  # index t ranges from n to N-1, inclusive on both ends\n",
    "  for t in range(n, N):\n",
    "    # get the n_gram preceding the word at position t\n",
    "    n_gram = sentence[t - n : t]\n",
    "\n",
    "    # get the word at position t\n",
    "    word = sentence[t]\n",
    "\n",
    "    # estimate the probability of the word given the n-gram using the n-gram counts, n-plus1-gram counts, vocabulary size and smoothing constant\n",
    "    probability = estimate_probability(word, n_gram, n_gram_counts, n_plus1_gram_counts, len(unique_words), k = 1)\n",
    "\n",
    "    # Update the product of the probabilities\n",
    "    # product_pi is the cumulative product of the (1/P) factors that are calculated in the loop\n",
    "    product_pi *= 1 / probability\n",
    "\n",
    "  # Take the N-th root of the product\n",
    "  perplexity = product_pi ** (1/float(N))\n",
    "\n",
    "  return perplexity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n37w34EFEBRb"
   },
   "outputs": [],
   "source": [
    "def mean_perplexity(sentences, n_gram_counts, n_plus1_gram_counts, vocabulary_size, k = 1.0, batch_size = 1000):\n",
    "  batch_sum = 0\n",
    "  batch_mean = 0\n",
    "\n",
    "  total_batch_number = 0\n",
    "  total_batch_mean = 0\n",
    "  \n",
    "  for i, sentence in enumerate(sentences):\n",
    "    perplexity = calculate_perplexity(sentence, n_gram_counts_list[0], n_gram_counts_list[1], len(vocabulary), k = 1.0)\n",
    "    batch_sum += perplexity\n",
    "    if(i % batch_size == 0):\n",
    "      batch_mean = batch_sum / batch_size\n",
    "      batch_sum = 0\n",
    "\n",
    "      total_batch_mean += batch_mean\n",
    "      total_batch_number += 1\n",
    "\n",
    "      print(f\"Batch Number : {total_batch_number}, Batch mean : {batch_mean}\")\n",
    "\n",
    "  return total_batch_mean / total_batch_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RTWoB_62TQD",
    "outputId": "71c7f60c-a184-4a9b-deb4-ca5afddc69ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.08595909384548"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the perplexity of first test data\n",
    "perplexity_test = calculate_perplexity(test_data[0], n_gram_counts_list[0], n_gram_counts_list[1], len(vocabulary), k = 1.0)\n",
    "perplexity_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpLj4GRwEBI-",
    "outputId": "32b09c3b-8388-4b6c-87b5-d8fd6ce72806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number : 1, Batch mean : 0.05008595909384548\n",
      "Batch Number : 2, Batch mean : 68.35781423300575\n",
      "Batch Number : 3, Batch mean : 68.72769120030458\n",
      "Batch Number : 4, Batch mean : 67.67094889782824\n",
      "Batch Number : 5, Batch mean : 69.22619189258396\n",
      "Batch Number : 6, Batch mean : 65.60438159287989\n",
      "Batch Number : 7, Batch mean : 67.90845419073437\n",
      "Batch Number : 8, Batch mean : 68.79992890053272\n",
      "Batch Number : 9, Batch mean : 68.34954337544801\n",
      "Batch Number : 10, Batch mean : 68.87837396706504\n",
      "Batch Number : 11, Batch mean : 66.51625779622\n",
      "Batch Number : 12, Batch mean : 70.48759558869985\n",
      "Batch Number : 13, Batch mean : 67.27051085202211\n",
      "Batch Number : 14, Batch mean : 67.85724720682443\n",
      "Batch Number : 15, Batch mean : 68.010417911914\n",
      "Batch Number : 16, Batch mean : 68.64593619837987\n",
      "Batch Number : 17, Batch mean : 68.97213384060413\n",
      "Batch Number : 18, Batch mean : 67.83659169911365\n",
      "Batch Number : 19, Batch mean : 68.17402582099915\n",
      "Batch Number : 20, Batch mean : 69.22088996587496\n",
      "Perplexity score of the model = 64.82825105450642\n"
     ]
    }
   ],
   "source": [
    "perplexity_test = mean_perplexity(test_data, n_gram_counts_list[0], n_gram_counts_list[1], len(vocabulary), k = 1.0)\n",
    "print(f\"Perplexity score of the model = {perplexity_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QajutcKSEA9e",
    "outputId": "84f62ca6-0101-4ac9-f2bc-5a143e07e787"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ऐलानी', 'जग्गामा', 'बस्ने', 'उनीहरूसँग', 'लालपुर्जा']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V0f08nEH1Siu",
    "outputId": "44381042-424d-451f-a1ce-ff5bcea1eea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ना', 'ख', 'नम्बरको', 'बाह्र', 'चक्के', 'ट्रकले', 'पैदल', 'हिँड्दै', 'गरेका', 'सोही', 'ठाउँमा', 'वर्षीय', 'चन्द्रमान', 'श्रेष्ठलाई', 'ठक्कर', 'दिँदा', 'उनको', 'घटनास्थलमै', 'ज्यान', 'गएको', 'ट्राफिक', 'प्रमुख', 'दयाराम', 'पौडेलले', 'बताए'], ['कुर्सी', 'जलाएपछि', 'जिल्ला', 'प्रहरी', 'कार्यालयको', 'टोलीले', 'संगठनका', 'पूर्व', 'जिल्ला', 'इन्चार्ज', 'सीके', 'भट्ट', 'र', 'वर्तमान', 'इन्चार्ज', 'भीम', 'भट्टलाई', 'गिरफ्तार', 'गरेको', 'छ'], ['दृढ', 'इच्छा', 'शक्ति', 'हुनुपर्छ', 'जनकपुरलाई', 'आधुनिक', 'सहर', 'बनाउन', 'सम्भव', 'छ'], ['यो', 'त', 'व्यक्तिका', 'लागि', 'व्यक्तिले', 'गर्ने', 'नितान्त', 'नीजी', 'मामला', 'हो'], ['अंग्रेजहरु', 'भारतमा', 'आउँदा', 'नबाबहरु', 'यति', 'कमजोर', 'हुन', 'थाले', 'कि', 'अब', 'हामी', 'शासन', 'गर्न', 'सक्दैनौँ', 'भन्ने', 'लाग्न', 'थाल्यो']]\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u8BQ26QT6FLH",
    "outputId": "3304c864-70eb-44ce-d262-502e79d3337d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGH21VzFEjnQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
